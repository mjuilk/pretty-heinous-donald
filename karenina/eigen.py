# Packagesimport pyranges as primport pandas as pdimport requestsimport timeimport networkx as nx# Initialise graphG = nx.Graph()# Load all input data## Variantsvariants_df = pd.read_csv("~/Documents/data/karenina/afm_cancer.tsv", sep="\t",                          names = ['chr', 'pos', 'ref', 'alt', 'gene', 'csq', 'rsid', 'maf'])variants_df = variants_df.iloc[1:]variants_df['weight'] = pd.to_numeric(variants_df['maf']) * 1000  # Scale for visibility##########CHANGE THIS SO THAT LOWER MAF MEANS HIGHER WEIGHT!!!!!#############variants_df = variants_df[~variants_df.alt.str.contains(",")] # Filter multiallelic rows## TSSpro_df = pd.read_csv("~/Documents/src/karenina/promote", sep="\t",                       names = ['chr', 'start', 'end', 'gene'])pro_df = pro_df[pro_df['gene'].isin(list(variants_df['gene']))]## Modsmod_df = pd.read_csv("~/Documents/data/karenina/rr3_chr13_17.bedmethyl", sep="\t",                     names = ['chr', 'pos', 'code', 'beta'])## Expressionexpression_df = pd.read_csv("~/Documents/data/karenina/expression.tsv", sep="\t",                            names=["gene", "expr"])expression_df["norm_expr"] = (expression_df["expr"] - expression_df["expr"].min()) / \                                  (expression_df["expr"].max() - expression_df["expr"].min())# Calculate anti-correlationmod_df['Start'] = mod_df['pos'].astype(int)mod_df['End'] = mod_df['Start'] + 1  # 1bp intervalmod_df = mod_df.rename(columns={'chr': 'Chromosome'})mod_df = mod_df[['Chromosome', 'Start', 'End', 'beta']]mod_pr = pr.PyRanges(mod_df)pro_df = pro_df.rename(columns={'chr': 'Chromosome', 'start': 'Start', 'end': 'End'})pro_df = pro_df[['Chromosome', 'Start', 'End', 'gene']]  # Keep only necessary columnspro_pr = pr.PyRanges(pro_df)overlap = mod_pr.join(pro_pr).dfoverlap['gene'] = overlap['gene'].astype(str)expression_df.index = expression_df.index.astype(str)expression_df = expression_df.set_index('gene')merged = overlap.merge(expression_df[['norm_expr']], left_on='gene', right_index=True, how='left')merged['anti_corr_score'] = -4 * (merged['norm_expr'] - 0.5) * (merged['beta'] - 0.5)# Pull PPIdef get_string_interactions(gene_list, species=9606, required_score=400):    base_url = "https://string-db.org/api/json/network"    interactions_dict = {}    for gene in gene_list:        params = {            "identifiers": gene,            "species": species,            "required_score": required_score        }        response = requests.get(base_url, params=params)        if response.status_code != 200:            print(f"Failed to fetch data for {gene}")            interactions_dict[gene] = []            continue        interactions = response.json()        partners = []        for interaction in interactions:            # STRING uses protein identifiers, which may differ; filter both ways            partner = interaction['preferredName_B'] if interaction['preferredName_A'] == gene else interaction['preferredName_A']            score = interaction['score']            partners.append((partner, score))        interactions_dict[gene] = partners        time.sleep(1)    return interactions_dict# Network constructionfor _, row in variants_df.iterrows():    variant_id = f"{row['rsid']}_{row['chr']}:{row['pos']}"    gene = row['gene']        # variant node    G.add_node(variant_id, type="variant", consequence = row['csq'])        # gene node    G.add_node(gene, type="gene")        # Add variant-gene edge    G.add_edge(variant_id, gene, relationship="variant_in_gene", weight = row['weight'])    for _, row in merged.iterrows():    meth_id = f"cg_{row['Chromosome']}:{row['Start']}"    gene = row['gene']        # meth node    G.add_node(meth_id, type="methylation", beta = row['beta'])        # gene node    G.add_node(gene, type="gene")        # meth-gene edge    G.add_edge(meth_id, gene, relationship="methylation_repression", weight=row['anti_corr_score'])genes_in_graph = [n for n in G.nodes if G.nodes[n].get('type') == 'gene']ppi_dict = get_string_interactions(genes_in_graph)for gene, partners in ppi_dict.items():    for partner, score in partners:        if G.has_edge(gene, partner):            # Optionally update score if needed            G[gene][partner]['score'] = max(G[gene][partner].get('score', 0), score)        else:            G.add_edge(gene, partner, score=score)# Compute centralitycentrality = nx.eigenvector_centrality(G, weight="weight", max_iter=10000)top_nodes = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:25]scaled_top_nodes = [(i[0], i[1] * 100)for i in top_nodes]print("Top central nodes:")for node, score in scaled_top_nodes:    print(f"{node}: {score:.3f}")deg_cent = nx.degree_centrality(G)bet_cent = nx.betweenness_centrality(G, weight="weight")#Cytoscape exportnx.write_graphml(G, "eigen.graphml")